{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 以下のtrainデータから特長量を作成し、学習モデルを生成させる。\n",
    "# /mnt/c/Users/hayat/Desktop/keiba_analysis/data_for_train/train/2005_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /mnt/c/Users/hayat/Desktop/keiba_analysis/data_for_train/train/2005_2022\n",
    "# のデータを取り込む\n",
    "\n",
    "import warnings\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import multiclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import scipy.stats\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_page_id = 2025050108\n",
    "\n",
    "is_denso = False\n",
    "# train_year_list = [\"2024\"]\n",
    "train_year_list = [\"2023\", \"2024\"]\n",
    "train_data = pd.DataFrame()\n",
    "horse_past_data = pd.DataFrame()\n",
    "horse_peds_data = pd.DataFrame()\n",
    "jockey_past_data = pd.DataFrame()\n",
    "for year in train_year_list:\n",
    "    train_path = '/home/hayato/horse_inference/data_for_train/train_data/' + year + '/'\n",
    "    if is_denso:\n",
    "        train_path = '/home/denso/horse_inference/data_for_train/train_data/' + year + '/'\n",
    "    # train dataに各年の学習データを縦方向に結合\n",
    "    train_data = pd.concat([train_data, pd.read_csv(train_path + \"train_data_results_\" + year + \".csv\", encoding='utf-8')], axis=0)\n",
    "    print(\"train data length {}\".format(len(train_data)))\n",
    "\n",
    "    # 勝率データ、過去のデータを取得\n",
    "    horse_past_data = pd.concat([horse_past_data, pd.read_csv(train_path + 'horse_results_' + year + '.csv', encoding='utf-8')], axis=0)\n",
    "    print(\"horse_past_data length {}\".format(len(horse_past_data)))\n",
    "    horse_peds_data = pd.concat([horse_peds_data, pd.read_csv(train_path + 'horse_born_results_' + year + '.csv', encoding='utf-8')], axis=0)\n",
    "    print(\"horse_peds_data length {}\".format(len(horse_peds_data)))\n",
    "    # ジョッキーの過去データを取得\n",
    "    jockey_past_data = pd.concat([jockey_past_data, pd.read_csv(train_path + 'jockey_results_' + year + '.csv', encoding='utf-8')], axis=0)\n",
    "    # jockeyデータはデータの中で\"累計\"が含まれているものだけを抽出\n",
    "    # \"年度\"列が\"累計\"の行だけを抽出\n",
    "    jockey_past_data = jockey_past_data[jockey_past_data['年度'] == '累計']\n",
    "    print(\"jockey_past_data length {}\".format(len(jockey_past_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horse_past_dataから最初のhorse_idの情報だけを抽出\n",
    "first_horse_past_data = horse_past_data.drop_duplicates(subset='horse_id', keep='first')\n",
    "# train_data = pd.merge(train_data, horse_peds_data, on='horse_id', how='left')\n",
    "\n",
    "# train dataに対してhorse_past_data、horse_peds_dataをhorse_idをキーにして結合\n",
    "train_data = pd.merge(train_data, first_horse_past_data, on='horse_id', how='left')\n",
    "# train dataの情報を表示\n",
    "print(train_data.info())\n",
    "# train dataのデータ長を表示\n",
    "print(\"train_data lenght :{}\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horse_peds_dataはpeds62がhorse_idなので、peds62をhorse_idに変更\n",
    "horse_peds_data = horse_peds_data.rename(columns={'peds_62': 'horse_id'})\n",
    "# すごい馬の血糖情報があるけどそんなにいらないので、5頭分のpeds0からpeds5までの情報だけを取得\n",
    "horse_peds_data = horse_peds_data[['horse_id', 'peds_0', 'peds_1', 'peds_2', 'peds_3', 'peds_4', 'peds_5']]\n",
    "# 1pedsに色んな情報が入っているので、半角スペースまでの情報だけを取得\n",
    "horse_peds_data['peds_0'] = horse_peds_data['peds_0'].apply(lambda x: x.split(' ')[0])\n",
    "horse_peds_data['peds_1'] = horse_peds_data['peds_1'].apply(lambda x: x.split(' ')[0])\n",
    "horse_peds_data['peds_2'] = horse_peds_data['peds_2'].apply(lambda x: x.split(' ')[0])\n",
    "horse_peds_data['peds_3'] = horse_peds_data['peds_3'].apply(lambda x: x.split(' ')[0])\n",
    "horse_peds_data['peds_4'] = horse_peds_data['peds_4'].apply(lambda x: x.split(' ')[0])\n",
    "horse_peds_data['peds_5'] = horse_peds_data['peds_5'].apply(lambda x: x.split(' ')[0])\n",
    "# train dataに対してhorse_peds_dataをhorse_idをキーにして結合\n",
    "train_data = pd.merge(train_data, horse_peds_data, on='horse_id', how='left')\n",
    "# train dataの情報を表示\n",
    "print(train_data.info())\n",
    "# train dataのデータ長を表示\n",
    "print(\"train_data lenght :{}\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataに対してjockey_past_dataをjockey_idをキーにして結合\n",
    "# jockey_resultsから必要なjockey_idの情報だけを抽出\n",
    "jockey_info = jockey_past_data[jockey_past_data['jockey_id'].isin(train_data['jockey_id'])]\n",
    "\n",
    "train_data = pd.merge(train_data, jockey_info, on='jockey_id', how='left')\n",
    "# train_data = pd.merge(train_data, jockey_past_data, on='jockey_id', how='left')\n",
    "print(train_data.info())\n",
    "# テスト的にtrain_dataのデータをcsvに保存\n",
    "train_data.to_csv(train_path + \"train_data_check.csv\", index=False, encoding='utf-8')\n",
    "print(\"train_data lenght :{}\".format(len(train_data)))\n",
    "train_data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataの重複をrace_id, horse_idで削除\n",
    "train_data = train_data.drop_duplicates(subset=[\"race_id\", \"horse_id\"], keep='first')\n",
    "# 重複をassertで確認\n",
    "assert train_data.duplicated(subset=[\"race_id\", \"horse_id\"]).sum() == 0\n",
    "\n",
    "# oddsだけ前処理の前に準備しておく\n",
    "train_data['単勝'] = train_data['単勝'].replace('---', 100)\n",
    "train_data['odds'] = train_data['単勝'].apply(lambda x: float(x))   \n",
    "train_data_for_ranking = train_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_data_path = \"/home/hayato/horse_inference/inference/\" + str(inference_page_id) + \"/add_dynamic_data/\"\n",
    "if is_denso:\n",
    "    inference_data_path = \"/home/denso/horse_inference/inference/\" + str(inference_page_id) + \"/add_dynamic_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()\n",
    "train_data_mlp = train_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "\n",
    "train_data = preprocess(train_data)\n",
    "# mlp用にコピーする\n",
    "train_data_mlp = preprocess(train_data_mlp, is_mlp=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レースごとのオッズの特長量変換\n",
    "# 追加する特長量\n",
    "# log_odds: オッズの対数\n",
    "# normalized_odds: オッズの正規化\n",
    "# zscore_odds: オッズのzscore\n",
    "# odds_rank: オッズの順位\n",
    "# odds_std: オッズの標準偏差\n",
    "train_data_for_ranking = odds_feature_engineering(train_data_for_ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各レースごとにオッズをソートして1位、2位、3位のオッズを取得\n",
    "# オッズの差分を計算して新しい特徴量として追加\n",
    "odds_diff_1_2, odds_diff_1_3 = get_odds_differences(train_data_for_ranking)\n",
    "train_data_for_ranking['odds_diff-1-2'] = odds_diff_1_2\n",
    "train_data_for_ranking['odds_diff-1-3'] = odds_diff_1_3\n",
    "\n",
    "# 結果を確認\n",
    "# print(train_data_for_ranking[['race_id', 'odds', 'odds_diff_1_2', 'odds_diff_1_3']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランキング学習での推論\n",
    "# step1 クエリを作成する\n",
    "# ランキング学習のためのクエリを作成\n",
    "\n",
    "# ============データ情報整理================\n",
    "# X_train: 学習用データ。クエリ必要\n",
    "# X_valid: 検証データ。クエリ必要\n",
    "# y_train: 学習用データの答え\n",
    "# y_valid: 検証データの答え\n",
    "# test_total: テストデータ。クエリ不要\n",
    "# y_test_true: テストデータの答え\n",
    "# ========================================\n",
    "# ランキング学習用のtrain dataを7:3で分割。この際データがばらばらに混ざってしまうので上から7割を学習データ、残りをテストデータとする\n",
    "train_ranking = train_data_for_ranking[:int(len(train_data_for_ranking)*0.7)]\n",
    "test_ranking = train_data_for_ranking[int(len(train_data_for_ranking)*0.7):]\n",
    "test_ranking_race_id = test_ranking[\"race_id\"]\n",
    "# train_rankingを7:3で分割。この際データがばらばらに混ざってしまうので上から7割を学習データ、残りをテストデータとする\n",
    "train_ranking = train_ranking[:int(len(train_ranking)*0.7)]\n",
    "valid_ranking = train_ranking[int(len(train_ranking)*0.7):]\n",
    "\n",
    "# trainデータのクエリを作成\n",
    "train_query, sorted_train_data = create_query(train_ranking,\"train\")\n",
    "# validデータのクエリを作成\n",
    "valid_query, sorted_valid_data = create_query(valid_ranking,\"valid\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クエリの数の合計を確認\n",
    "print(\"Number of queries in train data: {}\".format(sum(train_query)))\n",
    "print(\"Number of queries in valid data: {}\".format(sum(valid_query)))\n",
    "print(\"Total number of queries: {}\".format(len(train_query) + len(valid_query)))\n",
    "print(\"Number of rows in train data: {}\".format(len(sorted_train_data)))\n",
    "print(\"Number of rows in valid data: {}\".format(len(sorted_valid_data)))\n",
    "print(\"Total number of rows: {}\".format(len(sorted_train_data) + len(sorted_valid_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クエリを取得したので前処理をかける\n",
    "X_sorted_train_data = preprocess(sorted_train_data,is_ranking=True, is_mlp=True)\n",
    "X_sorted_valid_data = preprocess(sorted_valid_data,is_ranking=True, is_mlp=True)\n",
    "test_ranking = preprocess(test_ranking,is_ranking=True, is_mlp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクレイピングするごとにカラム名が変化してくので、カラム名のスペースを削除する処理を学習前に追加\n",
    "# X_sorted_train_data.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "X_sorted_train_data.columns = X_sorted_train_data.columns.str.replace(' ', '')\n",
    "X_sorted_train_data.columns = X_sorted_train_data.columns.str.replace('　', '')\n",
    "\n",
    "# X_sorted_valid_data.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "X_sorted_valid_data.columns = X_sorted_valid_data.columns.str.replace(' ', '')\n",
    "X_sorted_valid_data.columns = X_sorted_valid_data.columns.str.replace('　', '')\n",
    "\n",
    "# test_ranking.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "test_ranking.columns = test_ranking.columns.str.replace(' ', '')\n",
    "test_ranking.columns = test_ranking.columns.str.replace('　', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2位以下の予測のため学習データをコピーしておく\n",
    "X_sorted_train_data_copy = X_sorted_train_data.copy()\n",
    "X_sorted_valid_data_copy = X_sorted_valid_data.copy()\n",
    "test_ranking_copy = test_ranking.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# うまく目的変数の変換ができないので、現状のデータを見てみる\n",
    "# X_sorted_train_data.to_csv(\"X_sorted_train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sorted_train_dataにgoal_number_replaceを追加してcsvに保存する\n",
    "# X_sorted_train_data.to_csv(\"X_sorted_train_data_add_goal_number.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 目的変数goal_number_replaceを確保\n",
    "# 2. 実際のgoal_numberを確保\n",
    "# 3. goal_number_replaceを削除\n",
    "# 4. goal_numberを削除\n",
    "# 1========================================================\n",
    "y_train_ranking = X_sorted_train_data['goal_number_replace']\n",
    "y_valid_ranking = X_sorted_valid_data['goal_number_replace']\n",
    "y_test_true_ranking = test_ranking['goal_number_replace']\n",
    "# 2========================================================\n",
    "y_train_ranking_goal = X_sorted_train_data['goal_number']\n",
    "y_valid_ranking_goal = X_sorted_valid_data['goal_number']\n",
    "y_test_true_ranking_goal = test_ranking['goal_number']\n",
    "# 3========================================================\n",
    "X_sorted_train_data = X_sorted_train_data.drop('goal_number', axis=1)\n",
    "X_sorted_valid_data = X_sorted_valid_data.drop('goal_number', axis=1)\n",
    "test_ranking = test_ranking.drop('goal_number', axis=1)\n",
    "# 4========================================================\n",
    "X_sorted_train_data = X_sorted_train_data.drop('goal_number_replace', axis=1)\n",
    "X_sorted_valid_data = X_sorted_valid_data.drop('goal_number_replace', axis=1)\n",
    "test_ranking = test_ranking.drop('goal_number_replace', axis=1)\n",
    "# 5========================================================\n",
    "X_sorted_train_data = X_sorted_train_data.drop('race_id', axis=1)\n",
    "X_sorted_valid_data = X_sorted_valid_data.drop('race_id', axis=1)\n",
    "test_ranking = test_ranking.drop('race_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ\n",
    "X_sorted_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranking.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クエリの合計とデータの合計が一致しているか確認\n",
    "print(\"Number of queries in train data: {}\".format(sum(train_query)))\n",
    "print(\"Number of queries in valid data: {}\".format(sum(valid_query)))\n",
    "# y_train_rankingの数とX_sorted_train_dataの数が一致しているか確認\n",
    "print(\"y_train_ranking length {}\".format(len(y_train_ranking)))\n",
    "print(\"Number of rows in train data: {}\".format(len(X_sorted_train_data)))\n",
    "print(\"Number of rows in valid data: {}\".format(len(X_sorted_valid_data)))\n",
    "print(\"Total number of rows: {}\".format(len(X_sorted_train_data) + len(X_sorted_valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# データの準備\n",
    "# X_sorted_train_data, y_train_ranking, train_query\n",
    "# X_sorted_valid_data, y_valid_ranking, valid_query\n",
    "\n",
    "# ランキング学習\n",
    "model = lgb.LGBMRanker(\n",
    "    random_state=42,\n",
    "    objective='lambdarank',\n",
    "    metric='ndcg',\n",
    "    n_estimators=500,              # 決定木の個数(default:100) 5000のほうが10000より高い\n",
    "    learning_rate=0.1,            # 学習率(default:0.1)\n",
    "    num_leaves=10,                 # 決定木にある分岐の個数(default:31)\n",
    "    max_depth=10,                  # 決定木の深さの最大値(default:-1)\n",
    "    min_child_samples=40,         # 決定木のノードに含まれる最小サンプル数(default:20)\n",
    "    # feature_fraction=0.8,\n",
    "    # bagging_fraction=0.8,\n",
    "    # bagging_freq=10,\n",
    "    # lambda_l1=0.1,\n",
    "    # lambda_l2=0.1,\n",
    "    # min_split_gain=0.1,\n",
    "    # min_child_weight=0.1\n",
    "    # rambdalank_truncation_level=10,\n",
    "    max_position=3, # 3位までの順位を予測する,\n",
    "    # lambdarank_truncation_level = 5,\n",
    ")\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(\n",
    "    X_sorted_train_data,\n",
    "    y_train_ranking,\n",
    "    group=train_query,\n",
    "    eval_set=[(X_sorted_valid_data, y_valid_ranking)],\n",
    "    eval_group=[valid_query],\n",
    "    eval_at=[1, 2, 3],\n",
    "    eval_metric='ndcg',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング結果の取得\n",
    "evals_result = model.evals_result_\n",
    "\n",
    "# NDCGスコアのプロット\n",
    "# NDCGスコアは1になるほど予測モデルの性能が良いことを占める。1,3,5は上位何件の結果を反映するか。\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evals_result['valid_0']['ndcg@1'], label='NDCG@1')\n",
    "plt.plot(evals_result['valid_0']['ndcg@2'], label='NDCG@2')\n",
    "plt.plot(evals_result['valid_0']['ndcg@3'], label='NDCG@3')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('NDCG Score')\n",
    "plt.title('NDCG Score over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# model.best_iteration_のNDCGを数値で出力\n",
    "print(\"Best NDCG@1: {:.4f} in iteration: {}\".format(evals_result['valid_0']['ndcg@1'][model.best_iteration_ - 1], model.best_iteration_))\n",
    "print(\"Best NDCG@2: {:.4f} in iteration: {}\".format(evals_result['valid_0']['ndcg@2'][model.best_iteration_ - 1], model.best_iteration_))\n",
    "print(\"Best NDCG@3: {:.4f} in iteration: {}\".format(evals_result['valid_0']['ndcg@3'][model.best_iteration_ - 1], model.best_iteration_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アンサンブル候補①LightGBM(RankNet)\n",
    "# 学習データ： X_sorted_train_data, y_train_ranking\n",
    "# 学習データのクエリ： train_query\n",
    "# 検証データ： X_sorted_valid_data, y_valid_ranking\n",
    "# 検証データのクエリ： valid_query\n",
    "# テストデータ： test_ranking, y_test_true_ranking\n",
    "\n",
    "# LightGBMデータセット\n",
    "train_data = lgb.Dataset(X_sorted_train_data, label=y_train_ranking, group=train_query)\n",
    "valid_data = lgb.Dataset(X_sorted_valid_data, label=y_valid_ranking, group=valid_query)\n",
    "# パラメータの設定\n",
    "params = {\n",
    "    'objective': 'rank_xendcg',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_at': [1, 2, 3],\n",
    "    'n_estimators':1000,              # 決定木の個数(default:100) 5000のほうが10000より高い\n",
    "    'learning_rate':0.1,            # 学習率(default:0.1)\n",
    "    'num_leaves':10,                 # 決定木にある分岐の個数(default:31)\n",
    "    'max_depth':10,                  # 決定木の深さの最大値(default:-1)\n",
    "    \"max_position\":3, # 3位までの順位を予測する\n",
    "    \"min_data_in_leaf\":40,         # 決定木のノードに含まれる最小サンプル数(default:20)\n",
    "    # \"lambdarank_truncation_level\":5,\n",
    "}\n",
    "\n",
    "evaluation_results = {}\n",
    "# モデルの学習\n",
    "ranknet_model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[valid_data],\n",
    "    callbacks=[lgb.record_evaluation(evaluation_results)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 学習結果の可視化をndcgで行う\n",
    "# NDCGスコアのプロット\n",
    "# NDCGスコアは1になるほど予測モデルの性能が良いことを占める。1,3,5は上位何件の結果を反映するか。\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evaluation_results['valid_0']['ndcg@1'], label='NDCG@1')\n",
    "plt.plot(evaluation_results['valid_0']['ndcg@2'], label='NDCG@2')\n",
    "plt.plot(evaluation_results['valid_0']['ndcg@3'], label='NDCG@3')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('NDCG Score')\n",
    "plt.title('NDCG Score over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# model.best_iteration_のNDCGを数値で出力\n",
    "print(\"Best NDCG@1: {:.4f} in iteration: {}\".format(ranknet_model.best_score['valid_0']['ndcg@1'], ranknet_model.best_iteration))\n",
    "# 2も出力\n",
    "print(\"Best NDCG@2: {:.4f} in iteration: {}\".format(ranknet_model.best_score['valid_0']['ndcg@2'], ranknet_model.best_iteration))\n",
    "# 3も出力\n",
    "print(\"Best NDCG@3: {:.4f} in iteration: {}\".format(ranknet_model.best_score['valid_0']['ndcg@3'], ranknet_model.best_iteration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アンサンブル候補②XGBoost(Pairwise)\n",
    "from xgboost import XGBRanker\n",
    "# モデルの定義\n",
    "pairwise_model = XGBRanker(\n",
    "    objective='rank:pairwise',\n",
    "    eval_metric='ndcg',\n",
    "    n_estimators=1000,              # 決定木の個数(default:100) 5000のほうが10000より高い\n",
    "    learning_rate=0.1,            # 学習率(default:0.1)\n",
    "    max_depth=10,                    # 決定木の深さの最大値(default:6)\n",
    "    # subsample=0.8,                  # データのサンプリング比率(default:1)\n",
    "    # colsample_bytree=0.8,           # 列のサンプリング比率(default:1)\n",
    "    # min_child_weight=0.5,           # 葉の重みの最小値(default:1)\n",
    "    # reg_lambda=1.0,                 # L2正則化の強さ(default:1)\n",
    "    # gamma=0.1,                      # 葉の追加分岐を行うかの閾値(default:0)\n",
    "    # n_jobs=-1,                      # 並列処理の数(default:1)\n",
    "    random_state=42,                # 乱数のシード値(default:0)\n",
    "    max_position=3, # 3位までの順位を予測する\n",
    "    min_child_samples=30,         # 決定木のノードに含まれる最小サンプル数(default:20)\n",
    "    # lambdarank_truncation_level=5,\n",
    ")\n",
    "# モデルの学習\n",
    "pairwise_model.fit(\n",
    "    X_sorted_train_data,\n",
    "    y_train_ranking,\n",
    "    group=train_query,\n",
    "    eval_set=[(X_sorted_valid_data, y_valid_ranking)],\n",
    "    eval_group=[valid_query],\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "\n",
    "# 学習結果の可視化をndcgで行う\n",
    "# NDCGスコアのプロット\n",
    "# NDCGスコアは1になるほど予測モデルの性能が良いことを占める。1,3,5は上位何件の結果を反映するか。\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pairwise_model.evals_result()['validation_0']['ndcg'], label='NDCG')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('NDCG Score')\n",
    "plt.title('NDCG Score over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# model.best_iteration_のNDCGを数値で出力\n",
    "print(\"Best NDCG: {:.4f} in iteration: {}\".format(pairwise_model.best_score, pairwise_model.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　テストデータで推論\n",
    "# LighGBM(lambdarank)の推論\n",
    "prediction_test_ranking = model.predict(test_ranking, num_iteration=model.best_iteration_)\n",
    "# LightGBM(RankNet)の推論\n",
    "prediction_test_ranking_ranknet = ranknet_model.predict(test_ranking)\n",
    "# XGBoost(Pairwise)の推論\n",
    "prediction_test_ranking_pairwise = pairwise_model.predict(test_ranking)\n",
    "# 上記の平均をアンサンブルモデルとする\n",
    "prediction_test_ranking_ensemble = (prediction_test_ranking + prediction_test_ranking_ranknet + prediction_test_ranking_pairwise) / 3\n",
    "\n",
    "df_prediction_test_ranking = pd.DataFrame({\n",
    "    \"馬番号\": test_ranking[\"umaban\"],\n",
    "    \"予測スコア(lambdarank)\": prediction_test_ranking,\n",
    "    \"予測スコア(RankNet)\": prediction_test_ranking_ranknet,\n",
    "    \"予測スコア(Pairwise)\": prediction_test_ranking_pairwise,\n",
    "    \"ensemble_prediction\": prediction_test_ranking_ensemble,\n",
    "    \"着順関連度\": y_test_true_ranking,\n",
    "    \"着順\": y_test_true_ranking_goal,\n",
    "    \"race_id\": test_ranking_race_id,\n",
    "    \"distance\": test_ranking[\"distance\"],\n",
    "    \"ground_state\": test_ranking[\"ground_state\"],\n",
    "    \"weather\": test_ranking[\"weather\"],\n",
    "    \"condition\": test_ranking[\"condition\"],\n",
    "})\n",
    "\n",
    "\n",
    "# 同じレースidのうちスコアの大きい順に1位から予測順位を計算する\n",
    "df_prediction_test_ranking[\"予測順位(lambdarank)\"] = df_prediction_test_ranking.groupby(\"race_id\")[\"予測スコア(lambdarank)\"].rank(ascending=False, method='first')\n",
    "df_prediction_test_ranking[\"予測順位(RankNet)\"] = df_prediction_test_ranking.groupby(\"race_id\")[\"予測スコア(RankNet)\"].rank(ascending=False, method='first')\n",
    "df_prediction_test_ranking[\"予測順位(Pairwise)\"] = df_prediction_test_ranking.groupby(\"race_id\")[\"予測スコア(Pairwise)\"].rank(ascending=False, method='first')\n",
    "df_prediction_test_ranking[\"ensemble_prediction_rank\"] = df_prediction_test_ranking.groupby(\"race_id\")[\"ensemble_prediction\"].rank(ascending=False, method='first')\n",
    "# それぞれの予測順位はfloat型なのでint型に変換\n",
    "df_prediction_test_ranking[\"予測順位(lambdarank)\"] = df_prediction_test_ranking[\"予測順位(lambdarank)\"].astype(int)\n",
    "df_prediction_test_ranking[\"予測順位(RankNet)\"] = df_prediction_test_ranking[\"予測順位(RankNet)\"].astype(int)\n",
    "df_prediction_test_ranking[\"予測順位(Pairwise)\"] = df_prediction_test_ranking[\"予測順位(Pairwise)\"].astype(int)\n",
    "df_prediction_test_ranking[\"ensemble_prediction_rank\"] = df_prediction_test_ranking[\"ensemble_prediction_rank\"].astype(int)\n",
    "\n",
    "# 3つのモデルがすべて1位と判断したときだけ1位とするアンサンブルモデル\n",
    "# df_prediction_test_ranking['ensemble_prediction'] = (\n",
    "#     (df_prediction_test_ranking['予測順位(lambdarank)'] == 1) &\n",
    "#     (df_prediction_test_ranking['予測順位(RankNet)'] == 1) &\n",
    "#     (df_prediction_test_ranking['予測順位(Pairwise)'] == 1)\n",
    "# ).astype(int)\n",
    "\n",
    "# 予測スコアの分布を可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(prediction_test_ranking, bins=50, alpha=0.5, label='LightGBM(lambdarank)')\n",
    "plt.hist(prediction_test_ranking_ranknet, bins=50, alpha=0.5, label='LightGBM(RankNet)')\n",
    "plt.hist(prediction_test_ranking_pairwise, bins=50, alpha=0.5, label='XGBoost(Pairwise)')\n",
    "plt.hist(prediction_test_ranking_ensemble, bins=50, alpha=0.5, label='Ensemble')\n",
    "plt.xlabel('Predicted Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Predicted Score Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1位のスコアにおける予測結果の評価\n",
    "print(\"LightGBM(lambdarank)の評価\")\n",
    "rank_evaluation(df_prediction_test_ranking, '予測順位(lambdarank)')\n",
    "print(\"LightGBM(RankNet)の評価\")\n",
    "rank_evaluation(df_prediction_test_ranking, '予測順位(RankNet)')\n",
    "print(\"XGBoost(Pairwise)の評価\")\n",
    "rank_evaluation(df_prediction_test_ranking, '予測順位(Pairwise)')\n",
    "print(\"アンサンブルモデルの評価\")\n",
    "rank_evaluation(df_prediction_test_ranking, 'ensemble_prediction_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1位と2位のスコアの差を可視化する→閾値を決定してコンフュージョンマトリックスで正解率を確認する\n",
    "df_prediction_test_ranking['score_diff_lambdarank'] = calculate_score_diff(df_prediction_test_ranking, 'lambdarank')\n",
    "df_prediction_test_ranking['score_diff_RankNet'] = calculate_score_diff(df_prediction_test_ranking, 'RankNet')\n",
    "df_prediction_test_ranking['score_diff_Pairwise'] = calculate_score_diff(df_prediction_test_ranking, 'Pairwise')\n",
    "\n",
    "plot_score_diff(df_prediction_test_ranking, 'lambdarank', 1)\n",
    "plot_score_diff(df_prediction_test_ranking, 'RankNet', 1)\n",
    "plot_score_diff(df_prediction_test_ranking, 'Pairwise', 1)\n",
    "\n",
    "optimal_threshold_lambdarank, optimal_threshold_pr_lambdarank = find_optimal_threshold(df_prediction_test_ranking, 'lambdarank',1)\n",
    "optimal_threshold_ranknet, optimal_threshold_pr_ranknet = find_optimal_threshold(df_prediction_test_ranking, 'RankNet',1)\n",
    "optimal_threshold_pairwise, optimal_threshold_pr_pairwise = find_optimal_threshold(df_prediction_test_ranking, 'Pairwise',1)\n",
    "print(f'Optimal Threshold (ROC) for lambdarank: {optimal_threshold_lambdarank}')\n",
    "print(f'Optimal Threshold (Precision-Recall) for lambdarank: {optimal_threshold_pr_lambdarank}')\n",
    "print(f'Optimal Threshold (ROC) for RankNet: {optimal_threshold_ranknet}')\n",
    "print(f'Optimal Threshold (Precision-Recall) for RankNet: {optimal_threshold_pr_ranknet}')\n",
    "print(f'Optimal Threshold (ROC) for Pairwise: {optimal_threshold_pairwise}')\n",
    "print(f'Optimal Threshold (Precision-Recall) for Pairwise: {optimal_threshold_pr_pairwise}')\n",
    "\n",
    "df_prediction_test_ranking = apply_threshold(df_prediction_test_ranking, 'lambdarank', optimal_threshold_lambdarank)\n",
    "df_prediction_test_ranking = apply_threshold(df_prediction_test_ranking, 'RankNet', optimal_threshold_ranknet)\n",
    "df_prediction_test_ranking = apply_threshold(df_prediction_test_ranking, 'Pairwise', optimal_threshold_pairwise)\n",
    "\n",
    "evaluate_predictions(df_prediction_test_ranking, 'lambdarank')\n",
    "evaluate_predictions(df_prediction_test_ranking, 'RankNet')\n",
    "evaluate_predictions(df_prediction_test_ranking, 'Pairwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1位-2位のスコア/標準偏差を計算でやってみたけどrecallがあがってprecisionが下がる結果に。\n",
    "# ->未メンテ。\n",
    "# evaluate_predictions_std(df_prediction_test_ranking, 'lambdarank')\n",
    "# evaluate_predictions_std(df_prediction_test_ranking, 'RankNet')\n",
    "# evaluate_predictions_std(df_prediction_test_ranking, 'Pairwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果に対して距離、天気、馬場状態、コースの特長量ごとに予測精度が変わらないかを可視化する。\n",
    "model_evaluation_by_feature(df_prediction_test_ranking, 'lambdarank')\n",
    "model_evaluation_by_feature(df_prediction_test_ranking, 'RankNet')\n",
    "model_evaluation_by_feature(df_prediction_test_ranking, 'Pairwise')\n",
    "\n",
    "# condition\n",
    "# ['ダ' '芝' '障']\n",
    "# weather\n",
    "# ['小雨' '晴' '曇' '雨']\n",
    "# ground_state\n",
    "# ['不良' '稍重' '良' '重']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "   \n",
    "\n",
    "# 各モデルに対して馬連のprecisionを計算\n",
    "models = ['予測順位(lambdarank)', '予測順位(Pairwise)', '予測順位(RankNet)']\n",
    "for model_ in models:\n",
    "    umaren_precision(df_prediction_test_ranking, model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴重要度の可視化\n",
    "df_importance = pd.DataFrame({\"columns\": X_sorted_train_data.columns, \"importance\": model.feature_importances_})\n",
    "df_importance.sort_values(\"importance\", ascending=False, inplace=True)\n",
    "print(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カレントディレクトリにモデルを保存\n",
    "import pickle\n",
    "with open('pkl_registory/lambdarank_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "# カレントディレクトリにranknet_modelモデルを保存\n",
    "with open('pkl_registory/ranknet_model.pkl', 'wb') as f:\n",
    "    pickle.dump(ranknet_model, f)\n",
    "# カレントディレクトリにpairwise_modelモデルを保存\n",
    "with open('pkl_registory/pairwise_model.pkl', 'wb') as f:\n",
    "    pickle.dump(pairwise_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidates_for_second_inference(df, N):\n",
    "    # 3つのモデルが同じ順位を予測するか、3つのモデルのうち2つのモデルがN位と予測し、かつ予測スコア(lambdarank)が10以上のデータをNとして返す\n",
    "    candidates = df[\n",
    "        ((df[f'予測順位(lambdarank)'] == N) & (df[f'予測順位(RankNet)'] == N) & (df[f'予測順位(Pairwise)'] == N)) |\n",
    "        (((df[f'予測順位(lambdarank)'] == N) & (df[f'予測順位(RankNet)'] == N)) |\n",
    "         ((df[f'予測順位(lambdarank)'] == N) & (df[f'予測順位(Pairwise)'] == N)) |\n",
    "         ((df[f'予測順位(RankNet)'] == N) & (df[f'予測順位(Pairwise)'] == N))) &\n",
    "        (df[f'予測スコア(lambdarank)'] >= 10)\n",
    "    ]\n",
    "    \n",
    "    # 予測結果をNに設定\n",
    "    df[f'予測結果({N})'] = 0\n",
    "    df.loc[candidates.index, f'予測結果({N})'] = N\n",
    "    \n",
    "    return df\n",
    "\n",
    "def find_candidates_for_first(df, N):\n",
    "    # 3つのモデルのうち2つのモデルがN位と予測し、かつ予測スコア(lambdarank)が10以上のデータをNとして返す\n",
    "    candidates_two_models = df[\n",
    "        (((df[f'予測順位(lambdarank)'] == N) & (df[f'予測順位(RankNet)'] == N)) |\n",
    "         ((df[f'予測順位(lambdarank)'] == N) & (df[f'予測順位(Pairwise)'] == N)) |\n",
    "         ((df[f'予測順位(RankNet)'] == N) & (df[f'予測順位(Pairwise)'] == N)))\n",
    "    ]\n",
    "    \n",
    "    # 予測結果をNに設定\n",
    "    df[f'予測結果({N})'] = 0\n",
    "    df.loc[candidates_two_models.index, f'予測結果({N})'] = N\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_first_place_info(data, score_column, rank_column):\n",
    "        # 1位のスコアを取得\n",
    "        second_place = data[data[rank_column] == 1]\n",
    "        \n",
    "        if not second_place.empty:\n",
    "            for index, row in second_place.iterrows():\n",
    "                umaban = row['horse_id']\n",
    "                score = row[score_column]\n",
    "                rank = row[rank_column]\n",
    "                result = row['result'] if 'result' in row else 'N/A'\n",
    "                print(f\"Umaban: {umaban}, Score: {score}, Rank: {rank}, Result: {result}\")\n",
    "        else:\n",
    "            print(\"No second place found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from utils.utils_inference import *\n",
    "from utils.utils import *\n",
    "import os\n",
    "\n",
    "# 青色で出力\n",
    "# \"RankNetの正答率が高い\"\n",
    "print(\"\\033[34m二つのモデルで1位が出てくるときはオッズがつくならワイドあり\\033[0m\")\n",
    "# csvデータを1つずつ読み出し推論\n",
    "p = Path(inference_data_path)\n",
    "files = list(p.glob(\"*inference*.csv\"))\n",
    "print(p)\n",
    "print(files)\n",
    "count = 0\n",
    "for file in tqdm.tqdm(files):\n",
    "    # 読み込んだファイル名を出力\n",
    "    # print(\"=======予測ファイル名======== {}\".format(file))\n",
    "    print(\"=======予測ファイル名========\\n {}\".format(file))\n",
    "    inference_data = pd.read_csv(file, encoding='utf-8')\n",
    "    # データの確認\n",
    "    # print(inference_data.info())\n",
    "\n",
    "    # Unnamed: 0,class_list_in_raceを削除\n",
    "    # inference_data = inference_data.drop(['Unnamed: 0',\"class_list_in_race\",\"date\"], axis=1)\n",
    "    # inference_data.info()\n",
    "    inference_data['連対率'] = inference_data['連対率'].apply(\n",
    "        lambda x: float(x.replace('％', '')) if isinstance(x, str) and x.strip() not in ['％', '-'] else 0.0\n",
    "    )\n",
    "\n",
    "    # '勝率'列の値を処理し、全角の'％'を半角の'%'に置き換えてからfloatに変換\n",
    "    inference_data['勝率'] = inference_data['勝率'].apply(\n",
    "        lambda x: float(x.replace('％', '')) if isinstance(x, str) and x.strip() not in ['％', '-'] else 0.0\n",
    "    )\n",
    "    \n",
    "    # '複勝率'列の値を処理し、全角の'％'を半角の'%'に置き換えてからfloatに変換\n",
    "    inference_data['複勝率'] = inference_data['複勝率'].apply(\n",
    "        lambda x: float(x.replace('％', '')) if isinstance(x, str) and x.strip() not in ['％', '-'] else 0.0\n",
    "    )\n",
    "    #　=================real dataで推論=============================\n",
    "    inference_data, inference_data_odds, inference_data_race_id,inference_data_answer = preprocess_for_inference(inference_data)\n",
    "    # オッズの差分を計算して新しい特徴量として追加\n",
    "    inference_data = add_odds_differences_for_inference(inference_data)\n",
    "    \n",
    "\n",
    "    # X_sorted_train_data.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "    # X_sorted_train_data.columns = X_sorted_train_data.columns.str.replace(' ', '')\n",
    "    # X_sorted_train_data.columns = X_sorted_train_data.columns.str.replace('　', '')\n",
    "    \n",
    "\n",
    "    # inference_dataの特長量を設定する\n",
    "    inference_data_for_predict = inference_data[X_sorted_train_data.columns]\n",
    "\n",
    "    # ラベルエンコーディングは前処理終了後\n",
    "    # inference_dataの特長量のobject型は、LabelEncoderで数値に変換する\n",
    "    # object型の特長量を確認する\n",
    "    object_columns = inference_data_for_predict.select_dtypes(include='object').columns\n",
    "    object_columns\n",
    "    for column in object_columns:\n",
    "        le = LabelEncoder()\n",
    "        # object型は別のラベル名にてラベルエンコーディングする\n",
    "        inference_data_for_predict[column] = le.fit_transform(inference_data_for_predict[column])\n",
    "\n",
    "    # 対数変換実施\n",
    "    # inference_data = log_transform(inference_data)\n",
    "\n",
    "    # 標準化実施\n",
    "    # inference_data = standard_scaler(inference_data)\n",
    "\n",
    "    # モデル予測\n",
    "    prediction_inference_ranking = model.predict(inference_data_for_predict, num_iteration=model.best_iteration_)\n",
    "    prediction_inference_ranking_ranknet = ranknet_model.predict(inference_data_for_predict)\n",
    "    prediction_inference_ranking_pairwise = pairwise_model.predict(inference_data_for_predict)\n",
    "\n",
    "    inference_data[\"予測スコア(lambdarank)\"] = prediction_inference_ranking\n",
    "    inference_data[\"予測スコア(RankNet)\"] = prediction_inference_ranking_ranknet\n",
    "    inference_data[\"予測スコア(Pairwise)\"] = prediction_inference_ranking_pairwise\n",
    "    inference_data[\"goal_number\"] = inference_data_answer\n",
    "    # 2位予測用にデータを保存\n",
    "    inference_data.to_csv(file, index=False)\n",
    "\n",
    "    # シンプルに予測結果の平均を取る\n",
    "    prediction_inference = (prediction_inference_ranking + prediction_inference_ranking_ranknet + prediction_inference_ranking_pairwise) / 3\n",
    "    # データフレームを作成\n",
    "    df_prediction_test_ranking = pd.DataFrame({\n",
    "        \"horse_id\": inference_data[\"umaban\"],\n",
    "        \"予測スコア(lambdarank)\": prediction_inference_ranking,\n",
    "        \"予測スコア(RankNet)\": prediction_inference_ranking_ranknet,\n",
    "        \"予測スコア(Pairwise)\": prediction_inference_ranking_pairwise,\n",
    "        \"predict_amsamble\": prediction_inference,\n",
    "        \"odds\": inference_data_odds,\n",
    "        \"goal\": inference_data_answer,\n",
    "        \"race_id\": inference_data_race_id,\n",
    "        \"distance\": inference_data[\"distance\"],\n",
    "        \"condition\": inference_data[\"condition\"],\n",
    "        \"weather\": inference_data[\"weather\"],\n",
    "        \"ground_state\": inference_data[\"ground_state\"],\n",
    "    })\n",
    "\n",
    "    # 予測スコアの高い順にソート\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.sort_values(by=\"予測スコア(lambdarank)\", ascending=False)\n",
    "    # 予測順位を計算\n",
    "    df_prediction_test_ranking[\"予測順位(lambdarank)\"] = df_prediction_test_ranking[\"予測スコア(lambdarank)\"].rank(ascending=False, method='first').astype(int)\n",
    "    # 予測スコアの高い順にソート\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.sort_values(by=\"予測スコア(RankNet)\", ascending=False)\n",
    "    # 予測順位を計算\n",
    "    df_prediction_test_ranking[\"予測順位(RankNet)\"] = df_prediction_test_ranking[\"予測スコア(RankNet)\"].rank(ascending=False, method='first').astype(int)\n",
    "    # 予測スコアの高い順にソート\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.sort_values(by=\"予測スコア(Pairwise)\", ascending=False)\n",
    "    # 予測順位を計算\n",
    "    df_prediction_test_ranking[\"予測順位(Pairwise)\"] = df_prediction_test_ranking[\"予測スコア(Pairwise)\"].rank(ascending=False, method='first').astype(int)\n",
    "    # 予測スコアの高い順にソート\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.sort_values(by=\"predict_amsamble\", ascending=False)\n",
    "    # 予測順位を計算\n",
    "    df_prediction_test_ranking[\"予測順位(amsamble)\"] = df_prediction_test_ranking[\"predict_amsamble\"].rank(ascending=False, method='first').astype(int)\n",
    "    # インデックスをリセット\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.reset_index(drop=True)\n",
    "    # 最後に着順にソート\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.sort_values(by=\"goal\")\n",
    "\n",
    "    # 結果を確認\n",
    "    # print(df_prediction_test_ranking.head())\n",
    "    # pandasをcsvに保存\n",
    "    # inference_data_path + /inference_resultにディレクトリを作成し、csvを保存する\n",
    "    inference_data_path_result = inference_data_path + \"inference_result/\"\n",
    "    if not os.path.isdir(inference_data_path_result):\n",
    "        os.mkdir(inference_data_path_result)\n",
    "    file_name = file.name\n",
    "    saving_path = inference_data_path_result + \"prediction_\" +  str(file_name) + \"_.csv\"\n",
    "    # print(\"saving_path:{}\".format(saving_path))\n",
    "    df_prediction_test_ranking.to_csv(saving_path, index=False)\n",
    "\n",
    "    # 推論データに対して予測を行う。1位と2位のスコアの差を計算し、閾値を適用して各モデルごとに1位を予測する\n",
    "    df_prediction_test_ranking_ = prediction_print(df_prediction_test_ranking,optimal_threshold_lambdarank,optimal_threshold_ranknet,optimal_threshold_pairwise)\n",
    "    print(\"Candidate from multiple models\")\n",
    "    find_candidates_for_first(df_prediction_test_ranking,1)\n",
    "    print_first_place_info(df_prediction_test_ranking, \"予測スコア(RankNet)\", \"予測結果(1)\")\n",
    "    # =================================================================\n",
    "    # 予測結果がシビアすぎて全然買い目が出ないので過去の情報も一応出力しておく\n",
    "    # =================================================================\n",
    "    # すべてのモデルのスコアが正で1位かつスコアが0以上のものをフィルタリング\n",
    "    # utils_inference.add_prediction_info(df_prediction_test_ranking)\n",
    "\n",
    "    count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2位の予測モデルの生成\n",
    "# 各モデルのスコアを計算する関数\n",
    "def add_model_scores(data, model, model_name):\n",
    "    scores = model.predict(data[X_sorted_train_data.columns])\n",
    "    data[f'pred_score_{model_name}'] = scores\n",
    "    return data\n",
    "\n",
    "# 学習データにスコアを追加\n",
    "# X_sorted_train_data_copy = add_model_scores(X_sorted_train_data_copy, model, 'lambdarank')\n",
    "# X_sorted_train_data_copy = add_model_scores(X_sorted_train_data_copy, ranknet_model, 'RankNet')\n",
    "X_sorted_train_data_copy = add_model_scores(X_sorted_train_data_copy, pairwise_model, 'Pairwise')\n",
    "\n",
    "# 検証データにスコアを追加\n",
    "# X_sorted_valid_data_copy = add_model_scores(X_sorted_valid_data_copy, model, 'lambdarank')\n",
    "# X_sorted_valid_data_copy = add_model_scores(X_sorted_valid_data_copy, ranknet_model, 'RankNet')\n",
    "X_sorted_valid_data_copy = add_model_scores(X_sorted_valid_data_copy, pairwise_model, 'Pairwise')\n",
    "\n",
    "# テストデータにスコアを追加\n",
    "# test_ranking_copy = add_model_scores(test_ranking_copy, model, 'lambdarank')\n",
    "# test_ranking_copy = add_model_scores(test_ranking_copy, ranknet_model, 'RankNet')\n",
    "test_ranking_copy = add_model_scores(test_ranking_copy, pairwise_model, 'Pairwise')\n",
    "\n",
    "def add_race_features(data, model_name, race_id=True):\n",
    "    if race_id:\n",
    "        # 学習データでrace_idがクエリになるようにしている\n",
    "        groupby_obj = data.groupby(\"race_id\")\n",
    "    else:\n",
    "        # 推論データでrace_idがない場合は全体をグループ化\n",
    "        groupby_obj = data\n",
    "\n",
    "    if race_id:\n",
    "        # 1位のスコア\n",
    "        top_scores = groupby_obj[f'pred_score_{model_name}'].transform('max')\n",
    "        data[f'top_score_{model_name}'] = top_scores\n",
    "        \n",
    "        # 各馬のスコアと1位のスコアの差分\n",
    "        data[f'score_diff_{model_name}'] = top_scores - data[f'pred_score_{model_name}']\n",
    "        \n",
    "        # 1位と2位のスコアの差分\n",
    "        second_scores = groupby_obj[f'pred_score_{model_name}'].transform(lambda x: x.nlargest(2).iloc[-1])\n",
    "        data[f'top2_score_diff_{model_name}'] = top_scores - second_scores\n",
    "        \n",
    "        # レース内でのスコアの標準偏差\n",
    "        data[f'score_std_{model_name}'] = groupby_obj[f'pred_score_{model_name}'].transform('std')\n",
    "        \n",
    "        # レース内でのスコアの最大-最小\n",
    "        data[f'score_range_{model_name}'] = groupby_obj[f'pred_score_{model_name}'].transform(lambda x: x.max() - x.min())\n",
    "        \n",
    "        # 1位のスコアと平均スコアの差\n",
    "        mean_scores = groupby_obj[f'pred_score_{model_name}'].transform('mean')\n",
    "        data[f'top_mean_score_diff_{model_name}'] = top_scores - mean_scores\n",
    "        \n",
    "        # 上位3頭のスコアの平均\n",
    "        top3_mean_scores = groupby_obj[f'pred_score_{model_name}'].transform(lambda x: x.nlargest(3).mean())\n",
    "        data[f'top3_mean_score_{model_name}'] = top3_mean_scores\n",
    "        \n",
    "        # 2位以下のスコアの平均\n",
    "        below2_mean_scores = groupby_obj[f'pred_score_{model_name}'].transform(lambda x: x.nsmallest(len(x)-1).mean())\n",
    "        data[f'below2_mean_score_{model_name}'] = below2_mean_scores\n",
    "        \n",
    "        # 2位以下のスコアの標準偏差\n",
    "        below2_std_scores = groupby_obj[f'pred_score_{model_name}'].transform(lambda x: x.nsmallest(len(x)-1).std())\n",
    "        data[f'below2_score_std_{model_name}'] = below2_std_scores\n",
    "        \n",
    "        # 2位と3位のスコア差\n",
    "        third_scores = groupby_obj[f'pred_score_{model_name}'].transform(lambda x: x.nlargest(3).iloc[-1])\n",
    "        data[f'second_third_score_diff_{model_name}'] = second_scores - third_scores\n",
    "        \n",
    "        # 2位と最下位のスコア差\n",
    "        last_scores = groupby_obj[f'pred_score_{model_name}'].transform('min')\n",
    "        data[f'second_last_score_diff_{model_name}'] = second_scores - last_scores\n",
    "    else:\n",
    "        # 1位のスコア\n",
    "        top_score = data[f'pred_score_{model_name}'].max()\n",
    "        data[f'top_score_{model_name}'] = top_score\n",
    "        \n",
    "        # 各馬のスコアと1位のスコアの差分\n",
    "        data[f'score_diff_{model_name}'] = top_score - data[f'pred_score_{model_name}']\n",
    "        \n",
    "        # 1位と2位のスコアの差分\n",
    "        second_score = data[f'pred_score_{model_name}'].nlargest(2).iloc[-1]\n",
    "        data[f'top2_score_diff_{model_name}'] = top_score - second_score\n",
    "        \n",
    "        # スコアの標準偏差\n",
    "        score_std = data[f'pred_score_{model_name}'].std()\n",
    "        data[f'score_std_{model_name}'] = score_std\n",
    "        \n",
    "        # スコアの最大-最小\n",
    "        score_range = data[f'pred_score_{model_name}'].max() - data[f'pred_score_{model_name}'].min()\n",
    "        data[f'score_range_{model_name}'] = score_range\n",
    "        \n",
    "        # 1位のスコアと平均スコアの差\n",
    "        mean_score = data[f'pred_score_{model_name}'].mean()\n",
    "        data[f'top_mean_score_diff_{model_name}'] = top_score - mean_score\n",
    "        \n",
    "        # 上位3頭のスコアの平均\n",
    "        top3_mean_score = data[f'pred_score_{model_name}'].nlargest(3).mean()\n",
    "        data[f'top3_mean_score_{model_name}'] = top3_mean_score\n",
    "        \n",
    "        # 2位以下のスコアの平均\n",
    "        below2_mean_score = data[f'pred_score_{model_name}'].nsmallest(len(data)-1).mean()\n",
    "        data[f'below2_mean_score_{model_name}'] = below2_mean_score\n",
    "        \n",
    "        # 2位以下のスコアの標準偏差\n",
    "        below2_std_score = data[f'pred_score_{model_name}'].nsmallest(len(data)-1).std()\n",
    "        data[f'below2_score_std_{model_name}'] = below2_std_score\n",
    "        \n",
    "        # 2位と3位のスコア差\n",
    "        third_score = data[f'pred_score_{model_name}'].nlargest(3).iloc[-1]\n",
    "        data[f'second_third_score_diff_{model_name}'] = second_score - third_score\n",
    "        \n",
    "        # 2位と最下位のスコア差\n",
    "        last_score = data[f'pred_score_{model_name}'].min()\n",
    "        data[f'second_last_score_diff_{model_name}'] = second_score - last_score\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 学習データに特長量を追加\n",
    "# X_sorted_train_data_copy = add_race_features(X_sorted_train_data_copy, 'lambdarank')\n",
    "# X_sorted_train_data_copy = add_race_features(X_sorted_train_data_copy, 'RankNet')\n",
    "X_sorted_train_data_copy = add_race_features(X_sorted_train_data_copy, 'Pairwise')\n",
    "\n",
    "# 検証データに特長量を追加\n",
    "# X_sorted_valid_data_copy = add_race_features(X_sorted_valid_data_copy, 'lambdarank')\n",
    "# X_sorted_valid_data_copy = add_race_features(X_sorted_valid_data_copy, 'RankNet')\n",
    "X_sorted_valid_data_copy = add_race_features(X_sorted_valid_data_copy, 'Pairwise')\n",
    "\n",
    "# テストデータに特長量を追加\n",
    "# test_ranking_copy = add_race_features(test_ranking_copy, 'lambdarank')\n",
    "# test_ranking_copy = add_race_features(test_ranking_copy, 'RankNet')\n",
    "test_ranking_copy = add_race_features(test_ranking_copy, 'Pairwise')\n",
    "\n",
    "print(test_ranking_copy.columns)\n",
    "\n",
    "\n",
    "\n",
    "# pred_score_Pairwiseの逆数、対数化、標準化、正規化を行って性能改善するかを試す\n",
    "# X_sorted_train_data_copy[f'pred_score_Pairwise_inv'] = 1 / X_sorted_train_data_copy[f'pred_score_Pairwise']\n",
    "# X_sorted_valid_data_copy[f'pred_score_Pairwise_inv'] = 1 / X_sorted_valid_data_copy[f'pred_score_Pairwise']\n",
    "# test_ranking_copy[f'pred_score_Pairwise_inv'] = 1 / test_ranking_copy[f'pred_score_Pairwise']\n",
    "# X_sorted_train_data_copy[f'pred_score_Pairwise_log'] = np.log1p(X_sorted_train_data_copy[f'pred_score_Pairwise'])\n",
    "# X_sorted_valid_data_copy[f'pred_score_Pairwise_log'] = np.log1p(X_sorted_valid_data_copy[f'pred_score_Pairwise'])\n",
    "# test_ranking_copy[f'pred_score_Pairwise_log'] = np.log1p(test_ranking_copy[f'pred_score_Pairwise'])\n",
    "# X_sorted_train_data_copy[f'pred_score_Pairwise_std'] = (X_sorted_train_data_copy[f'pred_score_Pairwise'] - X_sorted_train_data_copy[f'pred_score_Pairwise'].mean()) / X_sorted_train_data_copy[f'pred_score_Pairwise'].std()\n",
    "# X_sorted_valid_data_copy[f'pred_score_Pairwise_std'] = (X_sorted_valid_data_copy[f'pred_score_Pairwise'] - X_sorted_valid_data_copy[f'pred_score_Pairwise'].mean()) / X_sorted_valid_data_copy[f'pred_score_Pairwise'].std()\n",
    "# test_ranking_copy[f'pred_score_Pairwise_std'] = (test_ranking_copy[f'pred_score_Pairwise'] - test_ranking_copy[f'pred_score_Pairwise'].mean()) / test_ranking_copy[f'pred_score_Pairwise'].std()\n",
    "# X_sorted_train_data_copy[f'pred_score_Pairwise_norm'] = (X_sorted_train_data_copy[f'pred_score_Pairwise'] - X_sorted_train_data_copy[f'pred_score_Pairwise'].min()) / (X_sorted_train_data_copy[f'pred_score_Pairwise'].max() - X_sorted_train_data_copy[f'pred_score_Pairwise'].min())\n",
    "# X_sorted_valid_data_copy[f'pred_score_Pairwise_norm'] = (X_sorted_valid_data_copy[f'pred_score_Pairwise'] - X_sorted_valid_data_copy[f'pred_score_Pairwise'].min()) / (X_sorted_valid_data_copy[f'pred_score_Pairwise'].max() - X_sorted_valid_data_copy[f'pred_score_Pairwise'].min())\n",
    "# test_ranking_copy[f'pred_score_Pairwise_norm'] = (test_ranking_copy[f'pred_score_Pairwise'] - test_ranking_copy[f'pred_score_Pairwise'].min()) / (test_ranking_copy[f'pred_score_Pairwise'].max() - test_ranking_copy[f'pred_score_Pairwise'].min())\n",
    "\n",
    "# pred_score_Pairwiseの特長量寄与度が高いのでいったんなしでどうなるか見てみる-> pairwiseのスコアとっても上がりました。\n",
    "X_sorted_train_data_copy.drop([f'pred_score_Pairwise'], axis=1, inplace=True)\n",
    "X_sorted_valid_data_copy.drop([f'pred_score_Pairwise'], axis=1, inplace=True)\n",
    "test_ranking_copy.drop([f'pred_score_Pairwise'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 着順1位の馬を削除\n",
    "# 学習データから1位の馬を削除\n",
    "def remove_top_horse(data):\n",
    "    # 着順が1位の馬を削除\n",
    "    data = data[data['goal_number'] != 1]\n",
    "    return data\n",
    "X_sorted_train_data_copy = remove_top_horse(X_sorted_train_data_copy)\n",
    "\n",
    "# 検証データから1位の馬を削除\n",
    "X_sorted_valid_data_copy = remove_top_horse(X_sorted_valid_data_copy)\n",
    "\n",
    "# テストデータから1位の馬を削除\n",
    "test_ranking_copy = remove_top_horse(test_ranking_copy)\n",
    "test_ranking_race_id = test_ranking_copy[\"race_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的関数であるgoal_number_replaceを振りなおす。\n",
    "# まずは1位の予測と同じ\n",
    "X_sorted_train_data_copy['goal_number_replace'] = X_sorted_train_data_copy['goal_number'].apply(\n",
    "    lambda x: 12 if x == 2 else (1 if x == 3 else 0))\n",
    "X_sorted_valid_data_copy['goal_number_replace'] = X_sorted_valid_data_copy['goal_number'].apply(\n",
    "    lambda x: 12 if x == 2 else (1 if x == 3 else 0))\n",
    "test_ranking_copy['goal_number_replace'] = test_ranking_copy['goal_number'].apply(\n",
    "    lambda x: 12 if x == 2 else (1 if x == 3 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1位の馬がなくなったのでクエリを振りなおし\n",
    "# trainデータのクエリを作成\n",
    "from utils.utils import create_query\n",
    "train_query, X_sorted_train_data_copy = create_query(X_sorted_train_data_copy,\"train\")\n",
    "# validデータのクエリを作成\n",
    "valid_query, X_sorted_valid_data_copy = create_query(X_sorted_valid_data_copy,\"valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1========================================================\n",
    "y_train_ranking = X_sorted_train_data_copy['goal_number_replace']\n",
    "y_valid_ranking = X_sorted_valid_data_copy['goal_number_replace']\n",
    "y_test_true_ranking = test_ranking_copy['goal_number_replace']\n",
    "# 2========================================================\n",
    "y_train_ranking_goal = X_sorted_train_data_copy['goal_number']\n",
    "y_valid_ranking_goal = X_sorted_valid_data_copy['goal_number']\n",
    "y_test_true_ranking_goal = test_ranking_copy['goal_number']\n",
    "# 3========================================================\n",
    "X_sorted_train_data_copy = X_sorted_train_data_copy.drop('goal_number', axis=1)\n",
    "X_sorted_valid_data_copy = X_sorted_valid_data_copy.drop('goal_number', axis=1)\n",
    "test_ranking_copy = test_ranking_copy.drop('goal_number', axis=1)\n",
    "# 4========================================================\n",
    "X_sorted_train_data_copy = X_sorted_train_data_copy.drop('goal_number_replace', axis=1)\n",
    "X_sorted_valid_data_copy = X_sorted_valid_data_copy.drop('goal_number_replace', axis=1)\n",
    "test_ranking_copy = test_ranking_copy.drop('goal_number_replace', axis=1)\n",
    "# 5========================================================\n",
    "X_sorted_train_data_copy = X_sorted_train_data_copy.drop('race_id', axis=1)\n",
    "X_sorted_valid_data_copy = X_sorted_valid_data_copy.drop('race_id', axis=1)\n",
    "test_ranking_copy = test_ranking_copy.drop('race_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクレイピングするごとにカラム名が変化してくので、カラム名のスペースを削除する処理を学習前に追加\n",
    "# X_sorted_train_data.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "X_sorted_train_data_copy.columns = X_sorted_train_data_copy.columns.str.replace(' ', '')\n",
    "X_sorted_train_data_copy.columns = X_sorted_train_data_copy.columns.str.replace('　', '')\n",
    "\n",
    "# X_sorted_valid_data.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "X_sorted_valid_data_copy.columns = X_sorted_valid_data_copy.columns.str.replace(' ', '')\n",
    "X_sorted_valid_data_copy.columns = X_sorted_valid_data_copy.columns.str.replace('　', '')\n",
    "\n",
    "# test_ranking.columnsの日本語文字列の半角、全角スペースを削除する\n",
    "test_ranking_copy.columns = test_ranking_copy.columns.str.replace(' ', '')\n",
    "test_ranking_copy.columns = test_ranking_copy.columns.str.replace('　', '')\n",
    "\n",
    "# データ確認用にX_sorted_train_data_copyを保存\n",
    "X_sorted_train_data_copy.to_csv(\"X_sorted_train_data_copy.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# データの準備\n",
    "# X_sorted_train_data, y_train_ranking, train_query\n",
    "# X_sorted_valid_data, y_valid_ranking, valid_query\n",
    "\n",
    "# ランキング学習\n",
    "lambdarank_model_second = lgb.LGBMRanker(\n",
    "    random_state=42,\n",
    "    objective='lambdarank',\n",
    "    metric='ndcg',\n",
    "    n_estimators=500,              # 決定木の個数(default:100) 5000のほうが10000より高い\n",
    "    learning_rate=0.1,            # 学習率(default:0.1)\n",
    "    num_leaves=10,                 # 決定木にある分岐の個数(default:31)\n",
    "    max_depth=10,                  # 決定木の深さの最大値(default:-1)\n",
    "    min_child_samples=40,         # 決定木のノードに含まれる最小サンプル数(default:20)\n",
    "    # feature_fraction=0.8,\n",
    "    # bagging_fraction=0.8,\n",
    "    # bagging_freq=10,\n",
    "    # lambda_l1=0.1,\n",
    "    # lambda_l2=0.1,\n",
    "    # min_split_gain=0.1,\n",
    "    # min_child_weight=0.1\n",
    "    # rambdalank_truncation_level=10,\n",
    "    max_position=3, # 3位までの順位を予測する,\n",
    "    # lambdarank_truncation_level = 5,\n",
    ")\n",
    "\n",
    "# モデルの学習\n",
    "lambdarank_model_second.fit(\n",
    "    X_sorted_train_data_copy,\n",
    "    y_train_ranking,\n",
    "    group=train_query,\n",
    "    eval_set=[(X_sorted_valid_data_copy, y_valid_ranking)],\n",
    "    eval_group=[valid_query],\n",
    "    eval_at=[1, 2, 3],\n",
    "    eval_metric='ndcg',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング結果の取得\n",
    "evals_result = lambdarank_model_second.evals_result_\n",
    "\n",
    "# NDCGスコアのプロット\n",
    "# NDCGスコアは1になるほど予測モデルの性能が良いことを占める。1,3,5は上位何件の結果を反映するか。\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evals_result['valid_0']['ndcg@1'], label='NDCG@1')\n",
    "plt.plot(evals_result['valid_0']['ndcg@2'], label='NDCG@2')\n",
    "plt.plot(evals_result['valid_0']['ndcg@3'], label='NDCG@3')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('NDCG Score')\n",
    "plt.title('NDCG Score over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# model.best_iteration_のNDCGを数値で出力\n",
    "print(\"Best NDCG@1: {:.4f} in iteration: {}\".format(evals_result['valid_0']['ndcg@1'][lambdarank_model_second.best_iteration_ - 1], lambdarank_model_second.best_iteration_))\n",
    "print(\"Best NDCG@2: {:.4f} in iteration: {}\".format(evals_result['valid_0']['ndcg@2'][lambdarank_model_second.best_iteration_ - 1], lambdarank_model_second.best_iteration_))\n",
    "print(\"Best NDCG@3: {:.4f} in iteration: {}\".format(evals_result['valid_0']['ndcg@3'][lambdarank_model_second.best_iteration_ - 1], lambdarank_model_second.best_iteration_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アンサンブル候補①LightGBM(RankNet)\n",
    "\n",
    "# LightGBMデータセット\n",
    "train_data = lgb.Dataset(X_sorted_train_data_copy, label=y_train_ranking, group=train_query)\n",
    "valid_data = lgb.Dataset(X_sorted_valid_data_copy, label=y_valid_ranking, group=valid_query)\n",
    "# パラメータの設定\n",
    "params = {\n",
    "    'objective': 'rank_xendcg',\n",
    "    'metric': 'ndcg',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.2,\n",
    "    'ndcg_at': [1, 2, 3],\n",
    "    'n_estimators':500,              # 決定木の個数(default:100) 5000のほうが10000より高い\n",
    "    'learning_rate':0.05,            # 学習率(default:0.1)\n",
    "    'max_depth':8,                  # 決定木の深さの最大値(default:-1)\n",
    "    \"min_data_in_leaf\":40,         # 決定木のノードに含まれる最小サンプル数(default:20)\n",
    "    \"lambdarank_truncation_level\":1,\n",
    "}\n",
    "\n",
    "evaluation_results = {}\n",
    "# モデルの学習\n",
    "ranknet_model_second = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[valid_data],\n",
    "    callbacks=[lgb.record_evaluation(evaluation_results)],\n",
    ")\n",
    "\n",
    "# 学習結果の可視化をndcgで行う\n",
    "# NDCGスコアのプロット\n",
    "# NDCGスコアは1になるほど予測モデルの性能が良いことを占める。1,3,5は上位何件の結果を反映するか。\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evaluation_results['valid_0']['ndcg@1'], label='NDCG@1')\n",
    "plt.plot(evaluation_results['valid_0']['ndcg@2'], label='NDCG@2')\n",
    "plt.plot(evaluation_results['valid_0']['ndcg@3'], label='NDCG@3')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('NDCG Score')\n",
    "plt.title('NDCG Score over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# model.best_iteration_のNDCGを数値で出力\n",
    "print(\"Best NDCG@1: {:.4f} in iteration: {}\".format(ranknet_model_second.best_score['valid_0']['ndcg@1'], ranknet_model_second.best_iteration))\n",
    "# 2も出力\n",
    "print(\"Best NDCG@2: {:.4f} in iteration: {}\".format(ranknet_model_second.best_score['valid_0']['ndcg@2'], ranknet_model_second.best_iteration))\n",
    "# 3も出力\n",
    "print(\"Best NDCG@3: {:.4f} in iteration: {}\".format(ranknet_model_second.best_score['valid_0']['ndcg@3'], ranknet_model_second.best_iteration))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アンサンブル候補②XGBoost(Pairwise)\n",
    "from xgboost import XGBRanker\n",
    "# モデルの定義\n",
    "pairwise_model_second = XGBRanker(\n",
    "    objective='rank:pairwise',\n",
    "    eval_metric='ndcg',\n",
    "    n_estimators=1000,              # 決定木の個数(default:100) 5000のほうが10000より高い\n",
    "    learning_rate=0.1,            # 学習率(default:0.1)\n",
    "    max_depth=10,                    # 決定木の深さの最大値(default:6)\n",
    "    # subsample=0.8,                  # データのサンプリング比率(default:1)\n",
    "    # colsample_bytree=0.8,           # 列のサンプリング比率(default:1)\n",
    "    # min_child_weight=0.5,           # 葉の重みの最小値(default:1)\n",
    "    # reg_lambda=1.0,                 # L2正則化の強さ(default:1)\n",
    "    # gamma=0.1,                      # 葉の追加分岐を行うかの閾値(default:0)\n",
    "    # n_jobs=-1,                      # 並列処理の数(default:1)\n",
    "    random_state=42,                # 乱数のシード値(default:0)\n",
    "    max_position=3, # 3位までの順位を予測する\n",
    "    min_child_samples=30,         # 決定木のノードに含まれる最小サンプル数(default:20)\n",
    "    # lambdarank_truncation_level=5,\n",
    ")\n",
    "# モデルの学習\n",
    "pairwise_model_second.fit(\n",
    "    X_sorted_train_data_copy,\n",
    "    y_train_ranking,\n",
    "    group=train_query,\n",
    "    eval_set=[(X_sorted_valid_data_copy, y_valid_ranking)],\n",
    "    eval_group=[valid_query],\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "\n",
    "# 学習結果の可視化をndcgで行う\n",
    "# NDCGスコアのプロット\n",
    "# NDCGスコアは1になるほど予測モデルの性能が良いことを占める。1,3,5は上位何件の結果を反映するか。\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pairwise_model_second.evals_result()['validation_0']['ndcg'], label='NDCG')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('NDCG Score')\n",
    "plt.title('NDCG Score over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# model.best_iteration_のNDCGを数値で出力\n",
    "print(\"Best NDCG: {:.4f} in iteration: {}\".format(pairwise_model_second.best_score, pairwise_model_second.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　テストデータで推論\n",
    "# LighGBM(lambdarank)の推論\n",
    "prediction_test_ranking = lambdarank_model_second.predict(test_ranking_copy, num_iteration=lambdarank_model_second.best_iteration_)\n",
    "# LightGBM(RankNet)の推論\n",
    "prediction_test_ranking_ranknet = ranknet_model_second.predict(test_ranking_copy)\n",
    "# XGBoost(Pairwise)の推論\n",
    "prediction_test_ranking_pairwise = pairwise_model_second.predict(test_ranking_copy)\n",
    "# 上記の平均をアンサンブルモデルとする\n",
    "prediction_test_ranking_ensemble = (prediction_test_ranking + prediction_test_ranking_ranknet + prediction_test_ranking_pairwise) / 3\n",
    "\n",
    "df_prediction_test_ranking = pd.DataFrame({\n",
    "    \"馬番号\": test_ranking_copy[\"umaban\"],\n",
    "    \"予測スコア(lambdarank)\": prediction_test_ranking,\n",
    "    \"予測スコア(RankNet)\": prediction_test_ranking_ranknet,\n",
    "    \"予測スコア(Pairwise)\": prediction_test_ranking_pairwise,\n",
    "    \"ensemble_prediction\": prediction_test_ranking_ensemble,\n",
    "    \"着順関連度\": y_test_true_ranking,\n",
    "    \"着順\": y_test_true_ranking_goal,\n",
    "    \"race_id\": test_ranking_race_id,\n",
    "    \"distance\": test_ranking_copy[\"distance\"],\n",
    "    \"ground_state\": test_ranking_copy[\"ground_state\"],\n",
    "    \"weather\": test_ranking_copy[\"weather\"],\n",
    "    \"condition\": test_ranking_copy[\"condition\"],\n",
    "})\n",
    "\n",
    "\n",
    "# 同じレースidのうちスコアの大きい順に1位から予測順位を計算する\n",
    "def rank_predictions(data, score_column, rank_column):\n",
    "    data[rank_column] = data.groupby(\"race_id\")[score_column].rank(ascending=False, method='first')\n",
    "    data[rank_column] = data.groupby(\"race_id\")[rank_column].transform(lambda x: x + 1)\n",
    "    return data\n",
    "# 予測順位をつける\n",
    "df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"予測スコア(lambdarank)\", \"予測順位(lambdarank)\")\n",
    "df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"予測スコア(RankNet)\", \"予測順位(RankNet)\")\n",
    "df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"予測スコア(Pairwise)\", \"予測順位(Pairwise)\")\n",
    "df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"ensemble_prediction\", \"ensemble_prediction_rank\")\n",
    "\n",
    "df_prediction_test_ranking[\"予測順位(lambdarank)\"] = df_prediction_test_ranking[\"予測順位(lambdarank)\"].astype(int)\n",
    "df_prediction_test_ranking[\"予測順位(RankNet)\"] = df_prediction_test_ranking[\"予測順位(RankNet)\"].astype(int)\n",
    "df_prediction_test_ranking[\"予測順位(Pairwise)\"] = df_prediction_test_ranking[\"予測順位(Pairwise)\"].astype(int)\n",
    "df_prediction_test_ranking[\"ensemble_prediction_rank\"] = df_prediction_test_ranking[\"ensemble_prediction_rank\"].astype(int)\n",
    "\n",
    "# 3つのモデルがすべて1位と判断したときだけ1位とするアンサンブルモデル\n",
    "# df_prediction_test_ranking['ensemble_prediction'] = (\n",
    "#     (df_prediction_test_ranking['予測順位(lambdarank)'] == 1) &\n",
    "#     (df_prediction_test_ranking['予測順位(RankNet)'] == 1) &\n",
    "#     (df_prediction_test_ranking['予測順位(Pairwise)'] == 1)\n",
    "# ).astype(int)\n",
    "\n",
    "# 予測スコアの分布を可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# XGBoost(Pairwise)のヒストグラム\n",
    "plt.hist(prediction_test_ranking_pairwise, bins=1, alpha=0.3, label='XGBoost(Pairwise)', color='blue')\n",
    "\n",
    "# LightGBM(lambdarank)のヒストグラム\n",
    "plt.hist(prediction_test_ranking, bins=50, alpha=0.3, label='LightGBM(lambdarank)', color='green')\n",
    "\n",
    "# LightGBM(RankNet)のヒストグラム\n",
    "plt.hist(prediction_test_ranking_ranknet, bins=50, alpha=0.3, label='LightGBM(RankNet)', color='red')\n",
    "\n",
    "plt.xlabel('Predicted Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Predicted Score Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 予測結果を保存\n",
    "df_prediction_test_ranking.to_csv(\"prediction_test_secandary_ranking.csv\", index=False)\n",
    "print(prediction_test_ranking_pairwise.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2位のスコアにおける予測結果の評価\n",
    "print(\"LightGBM(lambdarank)の評価\")\n",
    "rank_evaluation_N(df_prediction_test_ranking, '予測順位(lambdarank)')\n",
    "print(\"LightGBM(RankNet)の評価\")\n",
    "rank_evaluation_N(df_prediction_test_ranking, '予測順位(RankNet)')\n",
    "print(\"XGBoost(Pairwise)の評価\")\n",
    "rank_evaluation_N(df_prediction_test_ranking, '予測順位(Pairwise)')\n",
    "print(\"アンサンブルモデルの評価\")\n",
    "rank_evaluation_N(df_prediction_test_ranking, 'ensemble_prediction_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同じようなアプローチで2位と3位のスコアの差から2位の予測精度の向上にトライ\n",
    "# 1位と2位のスコアの差を可視化する→閾値を決定してコンフュージョンマトリックスで正解率を確認する\n",
    "df_prediction_test_ranking['score_diff_lambdarank'] = calculate_score_diff(df_prediction_test_ranking, 'lambdarank')\n",
    "df_prediction_test_ranking['score_diff_RankNet'] = calculate_score_diff(df_prediction_test_ranking, 'RankNet')\n",
    "df_prediction_test_ranking['score_diff_Pairwise'] = calculate_score_diff(df_prediction_test_ranking, 'Pairwise')\n",
    "\n",
    "plot_score_diff(df_prediction_test_ranking, 'lambdarank', 2)\n",
    "plot_score_diff(df_prediction_test_ranking, 'RankNet', 2)\n",
    "plot_score_diff(df_prediction_test_ranking, 'Pairwise', 2)\n",
    "\n",
    "optimal_threshold_lambdarank, optimal_threshold_pr_lambdarank = find_optimal_threshold(df_prediction_test_ranking, 'lambdarank', 2)\n",
    "optimal_threshold_ranknet, optimal_threshold_pr_ranknet = find_optimal_threshold(df_prediction_test_ranking, 'RankNet', 2)\n",
    "optimal_threshold_pairwise, optimal_threshold_pr_pairwise = find_optimal_threshold(df_prediction_test_ranking, 'Pairwise', 2)\n",
    "print(f'Optimal Threshold (ROC) for lambdarank: {optimal_threshold_lambdarank}')\n",
    "print(f'Optimal Threshold (Precision-Recall) for lambdarank: {optimal_threshold_pr_lambdarank}')\n",
    "print(f'Optimal Threshold (ROC) for RankNet: {optimal_threshold_ranknet}')\n",
    "print(f'Optimal Threshold (Precision-Recall) for RankNet: {optimal_threshold_pr_ranknet}')\n",
    "print(f'Optimal Threshold (ROC) for Pairwise: {optimal_threshold_pairwise}')\n",
    "print(f'Optimal Threshold (Precision-Recall) for Pairwise: {optimal_threshold_pr_pairwise}')\n",
    "\n",
    "df_prediction_test_ranking = apply_threshold_second(df_prediction_test_ranking, 'lambdarank', optimal_threshold_lambdarank)\n",
    "df_prediction_test_ranking = apply_threshold_second(df_prediction_test_ranking, 'RankNet', optimal_threshold_ranknet)\n",
    "df_prediction_test_ranking = apply_threshold_second(df_prediction_test_ranking, 'Pairwise', optimal_threshold_pairwise)\n",
    "\n",
    "print(\"LightGBM(lambdarank)の評価\")\n",
    "print(df_prediction_test_ranking['予測結果(lambdarank)'])\n",
    "rank_evaluation_N(df_prediction_test_ranking, '予測結果(lambdarank)')\n",
    "print(\"LightGBM(RankNet)の評価\")\n",
    "rank_evaluation_N(df_prediction_test_ranking, '予測結果(RankNet)')\n",
    "print(\"XGBoost(Pairwise)の評価\")\n",
    "rank_evaluation_N(df_prediction_test_ranking, '予測結果(Pairwise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴重要度の可視化\n",
    "df_importance = pd.DataFrame({\"columns\": X_sorted_train_data_copy.columns, \"importance\": pairwise_model_second.feature_importances_})\n",
    "df_importance.sort_values(\"importance\", ascending=False, inplace=True)\n",
    "print(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from utils.utils_inference import *\n",
    "\n",
    "# 青色で出力\n",
    "# \"RankNetの正答率が高い\"\n",
    "print(\"\\033[34m3つのモデルで1番または２つのモデルで1位かつlambdarankスコアが10以上を閾値とする\\033[0m\")\n",
    "# csvデータを1つずつ読み出し推論\n",
    "p = Path(inference_data_path)\n",
    "files = list(p.glob(\"*inference*.csv\"))\n",
    "print(p)\n",
    "print(files)\n",
    "count = 0\n",
    "for file in tqdm.tqdm(files):\n",
    "    # 読み込んだファイル名を出力\n",
    "    # print(\"=======予測ファイル名======== {}\".format(file))\n",
    "    print(\"=======予測ファイル名========\\n {}\".format(file))\n",
    "    inference_data = pd.read_csv(file, encoding='utf-8')\n",
    "    # データの確認\n",
    "    # print(inference_data.info())\n",
    "\n",
    "    # Unnamed: 0,class_list_in_raceを削除\n",
    "    # inference_data = inference_data.drop(['Unnamed: 0',\"class_list_in_race\",\"date\"], axis=1)\n",
    "\n",
    "    #　=================real dataで推論=============================\n",
    "    # inference_data, inference_data_odds, inference_data_race_id,inference_data_answer = preprocess_for_inference(inference_data,True)\n",
    "    # オッズの差分を計算して新しい特徴量として追加\n",
    "    inference_data = add_odds_differences_for_inference(inference_data)\n",
    "    \n",
    "    # 推論済みの特長量\"予測スコア(lambdarank)\"をpred_score_lambdarankに変更\n",
    "    inference_data = inference_data.rename(columns={'予測スコア(lambdarank)': 'pred_score_lambdarank'})\n",
    "    # 推論済みの特長量\"予測スコア(RankNet)\"をpred_score_RankNetに変更\n",
    "    inference_data = inference_data.rename(columns={'予測スコア(RankNet)': 'pred_score_RankNet'})\n",
    "    # 推論済みの特長量\"予測スコア(Pairwise)\"をpred_score_Pairwiseに変更\n",
    "    inference_data = inference_data.rename(columns={'予測スコア(Pairwise)': 'pred_score_Pairwise'})\n",
    "    # テストデータに特長量を追加\n",
    "    inference_data = add_race_features(inference_data, 'lambdarank', False)\n",
    "    inference_data = add_race_features(inference_data, 'RankNet', False)\n",
    "    inference_data = add_race_features(inference_data, 'Pairwise', False)\n",
    "\n",
    "    # 予測スコア1位の馬を削除\n",
    "    def remove_top_horse_no_race_id(data, model_name):\n",
    "        # 最大スコアの馬情報を取得\n",
    "        max_score = data[f'pred_score_{model_name}'].max()\n",
    "        \n",
    "        # 最大スコアの馬情報を削除\n",
    "        data = data[data[f'pred_score_{model_name}'] != max_score]\n",
    "        \n",
    "        return data\n",
    "    # 推論データから最大スコアの馬情報を削除\n",
    "    inference_data = remove_top_horse_no_race_id(inference_data, 'lambdarank')\n",
    "    inference_data = remove_top_horse_no_race_id(inference_data, 'RankNet')\n",
    "    inference_data = remove_top_horse_no_race_id(inference_data, 'Pairwise')\n",
    "    inference_data.info()\n",
    "    inference_data_odds = inference_data[\"odds\"]\n",
    "    # inference_dataの特長量を設定する\n",
    "    inference_data = inference_data[X_sorted_train_data_copy.columns]\n",
    "\n",
    "    # ラベルエンコーディングは前処理終了後\n",
    "    # inference_dataの特長量のobject型は、LabelEncoderで数値に変換する\n",
    "    # object型の特長量を確認する\n",
    "    object_columns = inference_data.select_dtypes(include='object').columns\n",
    "    object_columns\n",
    "    for column in object_columns:\n",
    "        # print(column)\n",
    "        le = LabelEncoder()\n",
    "        # object型は別のラベル名にてラベルエンコーディングする\n",
    "        inference_data[column] = le.fit_transform(inference_data[column])\n",
    "    # print(inference_data.info())\n",
    "\n",
    "    # 対数変換実施\n",
    "    # inference_data = log_transform(inference_data)\n",
    "\n",
    "    # 標準化実施\n",
    "    # inference_data = standard_scaler(inference_data)\n",
    "\n",
    "    # モデル予測\n",
    "    prediction_inference_ranking = lambdarank_model_second.predict(inference_data, num_iteration=lambdarank_model_second.best_iteration_)\n",
    "    prediction_inference_ranking_ranknet = ranknet_model_second.predict(inference_data)\n",
    "    prediction_inference_ranking_pairwise = pairwise_model_second.predict(inference_data)\n",
    "    # シンプルに予測結果の平均を取る\n",
    "    prediction_inference = (prediction_inference_ranking + prediction_inference_ranking_ranknet + prediction_inference_ranking_pairwise) / 3\n",
    "    # データフレームを作成\n",
    "    df_prediction_test_ranking = pd.DataFrame({\n",
    "        \"horse_id\": inference_data[\"umaban\"],\n",
    "        \"予測スコア(lambdarank)\": prediction_inference_ranking,\n",
    "        \"予測スコア(RankNet)\": prediction_inference_ranking_ranknet,\n",
    "        \"予測スコア(Pairwise)\": prediction_inference_ranking_pairwise,\n",
    "        \"predict_amsamble\": prediction_inference,\n",
    "        \"odds\": inference_data_odds,\n",
    "        \"distance\": inference_data[\"distance\"],\n",
    "        \"condition\": inference_data[\"condition\"],\n",
    "        \"weather\": inference_data[\"weather\"],\n",
    "        \"ground_state\": inference_data[\"ground_state\"],\n",
    "        \"race_id\":[\"test\"] * len(inference_data)\n",
    "    })\n",
    "\n",
    "    # 同じレースidのうちスコアの大きい順に1位から予測順位を計算する\n",
    "    def rank_predictions(data, score_column, rank_column):\n",
    "        data[rank_column] = data[score_column].rank(ascending=False, method='first')\n",
    "        data[rank_column] = data[rank_column].transform(lambda x: x + 1)\n",
    "        return data\n",
    "    # 予測順位をつける\n",
    "    df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"予測スコア(lambdarank)\", \"予測順位(lambdarank)\")\n",
    "    df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"予測スコア(RankNet)\", \"予測順位(RankNet)\")\n",
    "    df_prediction_test_ranking = rank_predictions(df_prediction_test_ranking, \"予測スコア(Pairwise)\", \"予測順位(Pairwise)\")\n",
    "\n",
    "    df_prediction_test_ranking[\"予測順位(lambdarank)\"] = df_prediction_test_ranking[\"予測順位(lambdarank)\"].astype(int)\n",
    "    df_prediction_test_ranking[\"予測順位(RankNet)\"] = df_prediction_test_ranking[\"予測順位(RankNet)\"].astype(int)\n",
    "    df_prediction_test_ranking[\"予測順位(Pairwise)\"] = df_prediction_test_ranking[\"予測順位(Pairwise)\"].astype(int)\n",
    "\n",
    "    # インデックスをリセット\n",
    "    df_prediction_test_ranking = df_prediction_test_ranking.reset_index(drop=True)\n",
    "\n",
    "    # 結果を確認\n",
    "    # print(df_prediction_test_ranking.head())\n",
    "    # pandasをcsvに保存\n",
    "    # inference_data_path + /inference_resultにディレクトリを作成し、csvを保存する\n",
    "    inference_data_path_result = inference_data_path + \"inference_result/\"\n",
    "    if not os.path.isdir(inference_data_path_result):\n",
    "        os.mkdir(inference_data_path_result)\n",
    "    file_name = file.name\n",
    "    saving_path = inference_data_path_result + \"prediction_second\" +  str(file_name) + \"_.csv\"\n",
    "    # print(\"saving_path:{}\".format(saving_path))\n",
    "    df_prediction_test_ranking.to_csv(saving_path, index=False)\n",
    "\n",
    "    # 推論データに対して予測を行う。1位と2位のスコアの差を計算し、閾値を適用して各モデルごとに1位を予測する\n",
    "    # df_prediction_test_ranking = prediction_print(df_prediction_test_ranking,optimal_threshold_lambdarank,optimal_threshold_ranknet,optimal_threshold_pairwise,2)\n",
    "    def print_second_place_info(data, score_column, rank_column):\n",
    "        # 2位のスコアを取得\n",
    "        second_place = data[data[rank_column] == 2]\n",
    "        \n",
    "        if not second_place.empty:\n",
    "            for index, row in second_place.iterrows():\n",
    "                umaban = row['horse_id']\n",
    "                score = row[score_column]\n",
    "                rank = row[rank_column]\n",
    "                result = row['result'] if 'result' in row else 'N/A'\n",
    "                print(f\"Umaban: {umaban}, Score: {score}, Rank: {rank}, Result: {result}\")\n",
    "        else:\n",
    "            print(\"No second place found.\")\n",
    "    # それぞれの予測結果、スコアを出力\n",
    "    print(\"lambdarank\")\n",
    "    # 2位の情報を出力\n",
    "    print_second_place_info(df_prediction_test_ranking, \"予測スコア(lambdarank)\", \"予測順位(lambdarank)\")\n",
    "    print(\"RankNet\")\n",
    "    print_second_place_info(df_prediction_test_ranking, \"予測スコア(RankNet)\", \"予測順位(RankNet)\")\n",
    "    print(\"Pairwise\")\n",
    "    print_second_place_info(df_prediction_test_ranking, \"予測スコア(Pairwise)\", \"予測順位(Pairwise)\")\n",
    "\n",
    "    find_candidates_for_second_inference(df_prediction_test_ranking, 2)\n",
    "    # 予測結果(2)の中で2位と予測された馬の情報を出力\n",
    "    print(\"Candidates for 2nd place\")\n",
    "    print_second_place_info(df_prediction_test_ranking, \"予測スコア(Pairwise)\", \"予測結果(2)\")\n",
    "\n",
    "    \n",
    "    count +=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
